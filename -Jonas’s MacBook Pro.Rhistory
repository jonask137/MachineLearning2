validation_steps = 50
)
model %>% save_model_hdf5("Saved Objects/cats_and_dogs_small_2.h5")
plot(history)
library(keras)
conv_base <- application_vgg16(
weights = "imagenet",
include_top = FALSE,
input_shape = c(150, 150, 3)
)
install.packages("h5py")
library(remotes)
install_github("cran/h5py")
library(pip)
library(keras)
conv_base <- application_vgg16(
weights = "imagenet",
include_top = FALSE,
input_shape = c(150, 150, 3)
)
conv_base
base_dir <- "~/Downloads/cats_and_dogs_small"
train_dir <- file.path(base_dir, "train")
validation_dir <- file.path(base_dir, "validation")
test_dir <- file.path(base_dir, "test")
datagen <- image_data_generator(rescale = 1/255)
batch_size <- 20
extract_features <- function(directory, sample_count) {
features <- array(0, dim = c(sample_count, 4, 4, 512))
labels <- array(0, dim = c(sample_count))
generator <- flow_images_from_directory(
directory = directory,
generator = datagen,
target_size = c(150, 150),
batch_size = batch_size,
class_mode = "binary"
)
i <- 0
while(TRUE) {
batch <- generator_next(generator)
inputs_batch <- batch[[1]]
labels_batch <- batch[[2]]
features_batch <- conv_base %>% predict(inputs_batch)
index_range <- ((i * batch_size)+1):((i + 1) * batch_size)
features[index_range,,,] <- features_batch
labels[index_range] <- labels_batch
i <- i + 1
if (i * batch_size >= sample_count)
break                                                1
}
list(
features = features,
labels = labels
)
}
extract_features <- function(directory, sample_count) {
features <- array(0, dim = c(sample_count, 4, 4, 512))
labels <- array(0, dim = c(sample_count))
generator <- flow_images_from_directory(
directory = directory,
generator = datagen,
target_size = c(150, 150),
batch_size = batch_size,
class_mode = "binary"
)
i <- 0
while(TRUE) {
batch <- generator_next(generator)
inputs_batch <- batch[[1]]
labels_batch <- batch[[2]]
features_batch <- conv_base %>% predict(inputs_batch)
index_range <- ((i * batch_size)+1):((i + 1) * batch_size)
features[index_range,,,] <- features_batch
labels[index_range] <- labels_batch
i <- i + 1
if (i * batch_size >= sample_count)
break
}
list(
features = features,
labels = labels
)
}
train <- extract_features(train_dir, 2000)
validation <- extract_features(validation_dir, 1000)
validation_dir
validation_dir
train <- extract_features(train_dir, 2000)
(i + 1) * batch_size
train_dir
file.path(base_dir, "train")
model <- load_model_hdf5("Saved Objects/cats_and_dogs_small_2.h5")
model
base_dir <- "Data/3. Deep Learning/cats_and_dogs_small"
train_dir <- file.path(base_dir, "train")
validation_dir <- file.path(base_dir, "validation")
test_dir <- file.path(base_dir, "test")
datagen <- image_data_generator(rescale = 1/255)
batch_size <- 20
extract_features <- function(directory, sample_count) {
features <- array(0, dim = c(sample_count, 4, 4, 512))
labels <- array(0, dim = c(sample_count))
generator <- flow_images_from_directory(
directory = directory,
generator = datagen,
target_size = c(150, 150),
batch_size = batch_size,
class_mode = "binary"
)
i <- 0
while(TRUE) {
batch <- generator_next(generator)
inputs_batch <- batch[[1]]
labels_batch <- batch[[2]]
features_batch <- conv_base %>% predict(inputs_batch)
index_range <- ((i * batch_size)+1):((i + 1) * batch_size)
features[index_range,,,] <- features_batch
labels[index_range] <- labels_batch
i <- i + 1
if (i * batch_size >= sample_count)
break
}
list(
features = features,
labels = labels
)
}
train <- extract_features(train_dir, 2000)
validation <- extract_features(validation_dir, 1000)
test <- extract_features(test_dir, 1000)
reshape_features <- function(features) {
array_reshape(features, dim = c(nrow(features), 4 * 4 * 512))
}
train$features <- reshape_features(train$features)
validation$features <- reshape_features(validation$features)
test$features <- reshape_features(test$features)
#Defining and training the densely connected classifier
model <- keras_model_sequential() %>%
layer_dense(units = 256, activation = "relu",
input_shape = 4 * 4 * 512) %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 1, activation = "sigmoid")
model %>% compile(
optimizer = optimizer_rmsprop(lr = 2e-5),
loss = "binary_crossentropy",
metrics = c("accuracy")
)
history <- model %>% fit(
train$features, train$labels,
epochs = 30,
batch_size = 20,
validation_data = list(validation$features, validation$labels)
)
plot(history)
img_path <- "Data/3. Deep Learning/cats_and_dogs_small/test/cats/cat.1700.jpg"
img <- image_load(img_path, target_size = c(150, 150))
img_tensor <- image_to_array(img)
img_tensor <- array_reshape(img_tensor, c(1, 150, 150, 3))
img_tensor <- img_tensor / 255
dim(img_tensor)
plot(as.raster(img_tensor[1,,,]))
layer_outputs <- lapply(model$layers[1:8], function(layer) layer$output)
activation_model <- keras_model(inputs = model$input, outputs = layer_outputs)
activation_model <- keras_model(inputs = model$input, outputs = layer_outputs)
layer_outputs <- lapply(model$layers[1:8], function(layer) layer$output)
activation_model <- keras_model(inputs = model$input, outputs = layer_outputs)
model$input
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
dir.create("images")
library(keras)
library(keras)
model <- load_model_hdf5("Saved Objects/cats_and_dogs_small_2.h5")
load_model_hdf5("Saved Objects/cats_and_dogs_small_2.h5")
model <- load_model_hdf5("Saved Objects/cats_and_dogs_small_2.h5")
getwd()
model <- load_model_hdf5("~/OneDrive/OneDrive/AU - Business Intelligence/Machine Learning for Business Intelligence 2/MachineLearning2/Saved Objectscats_and_dogs_small_2.h5")
library(keras)
model <- load_model_hdf5("Saved Objects/cats_and_dogs_small_2.h5")
model
model <- load_model_hdf5("Saved Objects/cats_and_dogs_small_2.h5")
summary(model)  # As a reminder.
img_path <- "~/Images/Cats and dogs/test/cats/cat.1700.jpg"
# We preprocess the image into a 4D tensor
img <- image_load(img_path, target_size = c(150, 150))
img_path <- "~/Data/3. Deep Learning/cats_and_dogs_small/test/cats/cat.1700.jpg"
# We preprocess the image into a 4D tensor
img <- image_load(img_path, target_size = c(150, 150))
img_path <- "~/Data/3. Deep Learning/cats_and_dogs_small/test/cats/cat.1700.jpg"
img_path <- "Data/3. Deep Learning/cats_and_dogs_small/test/cats/cat.1700.jpg"
# We preprocess the image into a 4D tensor
img <- image_load(img_path, target_size = c(150, 150))
img_path <- "Data/3. Deep Learning/cats_and_dogs_small/test/cats/cat.1700.jpg"
img <- image_load(img_path, target_size = c(150, 150))
img_path <- "Data/3. Deep Learning/cats_and_dogs_small/test/cats/cat.1700.jpg"
img <- image_load(img_path, target_size = c(150, 150))
img_tensor <- image_to_array(img)
img_tensor <- array_reshape(img_tensor, c(1, 150, 150, 3))
img_tensor <- img_tensor / 255
dim(img_tensor)
plot(as.raster(img_tensor[1,,,]))
library(keras)
model <- application_vgg16(
weights = "imagenet",
include_top = FALSE
)
layer_name <- "block3_conv1"
filter_index <- 1
layer_output <- get_layer(model, layer_name)$output
loss <- k_mean(layer_output[,,,filter_index])
# The call to `gradients` returns a list of tensors (of size 1 in this case)
# hence we only keep the first element -- which is a tensor.
grads <- k_gradients(loss, model$input)[[1]]
demo)=
demo()
library(doParallel)
corecount <- makePSOCKcluster(detectCores()-1)
registerDoParallel(corecount)
conv_base <- application_vgg19(
weights = "imagenet",
include_top = FALSE, #Do we want the densely connected layers?
input_shape = c(150, 150, 3)
)
conv_base
#' Note, loaded all the directories again.
##### Loading images
#' In the following we are loading the images, notice that we are not doing
#' any image augmentation. Data Augmentation is a very heavy process and cant
#' run on the mac.
datagen <- image_data_generator(rescale = 1/255)
batch_size <- 10
extract_features <- function(directory, sample_count) {
features <- array(0, dim = c(sample_count, 4, 4, 512)) #Creates an empty array
labels <- array(0, dim = c(sample_count)) #Creates an empty array
generator <- flow_images_from_directory(
directory = directory,
generator = datagen,
target_size = c(150, 150),
batch_size = batch_size,
class_mode = "binary" #Categorical returns a one-hot encoded matrix, we need a vector
)
i <- 0
while(TRUE) {
print(cat(i,"th loop begin"))
batch <- generator_next(generator)
inputs_batch <- batch[[1]]
labels_batch <- batch[[2]]
features_batch <- conv_base %>% predict(inputs_batch)
index_range <- ((i * batch_size)+1):((i + 1) * batch_size) #Define the range to be loaded into
features[index_range,,,] <- features_batch #Loads features into the index range in the object featurs
labels[index_range] <- labels_batch #Same principle as above
# This step appear to take the first column from the one-hot encoded
i <- i + 1
print(i)
if (i * batch_size >= sample_count)
break
}
list(
features = features,
labels = labels
)
}
train <- extract_features(train_dir
, 4830) #This is the amount of picturs. There are in fact 4838, but for some reason this does not work
validation <- extract_features(validation_dir, 1380) #there is 1388
test <- extract_features(test_dir, 680) #There are 681
##### Flatting the layers ----
#' We want to flatten the layers, so we can use them as input for the
#' densely connected layers.
reshape_features <- function(features) {
array_reshape(features, dim = c(nrow(features), 4 * 4 * 512))
}
train$features <- reshape_features(train$features)
validation$features <- reshape_features(validation$features)
test$features <- reshape_features(test$features)
##### Validating the model ----
#Defining and training the densely connected classifier
model <- keras_model_sequential() %>%
layer_dense(units = 512, activation = "relu",
input_shape = 4 * 4 * 512) %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 8, activation = "softmax")
model %>% compile(
optimizer = 'Adagrad',
loss = "binary_crossentropy",
metrics = c("accuracy")
)
history <- model %>% fit(
train$features, train$labels,
epochs = 30,
batch_size = 20,
validation_data = list(validation$features, validation$labels)
)
library(dplyr)
conv_base <- application_vgg19(
weights = "imagenet",
include_top = FALSE, #Do we want the densely connected layers?
input_shape = c(150, 150, 3)
)
conv_base
#' Note, loaded all the directories again.
##### Loading images
#' In the following we are loading the images, notice that we are not doing
#' any image augmentation. Data Augmentation is a very heavy process and cant
#' run on the mac.
datagen <- image_data_generator(rescale = 1/255)
batch_size <- 10
extract_features <- function(directory, sample_count) {
features <- array(0, dim = c(sample_count, 4, 4, 512)) #Creates an empty array
labels <- array(0, dim = c(sample_count)) #Creates an empty array
generator <- flow_images_from_directory(
directory = directory,
generator = datagen,
target_size = c(150, 150),
batch_size = batch_size,
class_mode = "binary" #Categorical returns a one-hot encoded matrix, we need a vector
)
i <- 0
while(TRUE) {
print(cat(i,"th loop begin"))
batch <- generator_next(generator)
inputs_batch <- batch[[1]]
labels_batch <- batch[[2]]
features_batch <- conv_base %>% predict(inputs_batch)
index_range <- ((i * batch_size)+1):((i + 1) * batch_size) #Define the range to be loaded into
features[index_range,,,] <- features_batch #Loads features into the index range in the object featurs
labels[index_range] <- labels_batch #Same principle as above
# This step appear to take the first column from the one-hot encoded
i <- i + 1
print(i)
if (i * batch_size >= sample_count)
break
}
list(
features = features,
labels = labels
)
}
train <- extract_features(train_dir
, 4830) #This is the amount of picturs. There are in fact 4838, but for some reason this does not work
validation <- extract_features(validation_dir, 1380) #there is 1388
test <- extract_features(test_dir, 680) #There are 681
##### Flatting the layers ----
#' We want to flatten the layers, so we can use them as input for the
#' densely connected layers.
reshape_features <- function(features) {
array_reshape(features, dim = c(nrow(features), 4 * 4 * 512))
}
train$features <- reshape_features(train$features)
validation$features <- reshape_features(validation$features)
test$features <- reshape_features(test$features)
##### Validating the model ----
#Defining and training the densely connected classifier
model <- keras_model_sequential() %>%
layer_dense(units = 512, activation = "relu",
input_shape = 4 * 4 * 512) %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 8, activation = "softmax")
model %>% compile(
optimizer = 'Adagrad',
loss = "binary_crossentropy",
metrics = c("accuracy")
)
history <- model %>% fit(
train$features, train$labels,
epochs = 30,
batch_size = 20,
validation_data = list(validation$features, validation$labels)
)
library(keras)
conv_base <- application_vgg19(
weights = "imagenet",
include_top = FALSE, #Do we want the densely connected layers?
input_shape = c(150, 150, 3)
)
conv_base
#' Note, loaded all the directories again.
##### Loading images
#' In the following we are loading the images, notice that we are not doing
#' any image augmentation. Data Augmentation is a very heavy process and cant
#' run on the mac.
datagen <- image_data_generator(rescale = 1/255)
batch_size <- 10
extract_features <- function(directory, sample_count) {
features <- array(0, dim = c(sample_count, 4, 4, 512)) #Creates an empty array
labels <- array(0, dim = c(sample_count)) #Creates an empty array
generator <- flow_images_from_directory(
directory = directory,
generator = datagen,
target_size = c(150, 150),
batch_size = batch_size,
class_mode = "binary" #Categorical returns a one-hot encoded matrix, we need a vector
)
i <- 0
while(TRUE) {
print(cat(i,"th loop begin"))
batch <- generator_next(generator)
inputs_batch <- batch[[1]]
labels_batch <- batch[[2]]
features_batch <- conv_base %>% predict(inputs_batch)
index_range <- ((i * batch_size)+1):((i + 1) * batch_size) #Define the range to be loaded into
features[index_range,,,] <- features_batch #Loads features into the index range in the object featurs
labels[index_range] <- labels_batch #Same principle as above
# This step appear to take the first column from the one-hot encoded
i <- i + 1
print(i)
if (i * batch_size >= sample_count)
break
}
list(
features = features,
labels = labels
)
}
train <- extract_features(train_dir
, 4830) #This is the amount of picturs. There are in fact 4838, but for some reason this does not work
validation <- extract_features(validation_dir, 1380) #there is 1388
test <- extract_features(test_dir, 680) #There are 681
##### Flatting the layers ----
#' We want to flatten the layers, so we can use them as input for the
#' densely connected layers.
reshape_features <- function(features) {
array_reshape(features, dim = c(nrow(features), 4 * 4 * 512))
}
train$features <- reshape_features(train$features)
validation$features <- reshape_features(validation$features)
test$features <- reshape_features(test$features)
##### Validating the model ----
#Defining and training the densely connected classifier
model <- keras_model_sequential() %>%
layer_dense(units = 512, activation = "relu",
input_shape = 4 * 4 * 512) %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 8, activation = "softmax")
model %>% compile(
optimizer = 'Adagrad',
loss = "binary_crossentropy",
metrics = c("accuracy")
)
history <- model %>% fit(
train$features, train$labels,
epochs = 30,
batch_size = 20,
validation_data = list(validation$features, validation$labels)
)
datagen <- image_data_generator(rescale = 1/255)
batch_size <- 10
extract_features <- function(directory, sample_count) {
features <- array(0, dim = c(sample_count, 4, 4, 512)) #Creates an empty array
labels <- array(0, dim = c(sample_count)) #Creates an empty array
generator <- flow_images_from_directory(
directory = directory,
generator = datagen,
target_size = c(150, 150),
batch_size = batch_size,
class_mode = "binary" #Categorical returns a one-hot encoded matrix, we need a vector
)
i <- 0
while(TRUE) {
print(cat(i,"th loop begin"))
batch <- generator_next(generator)
inputs_batch <- batch[[1]]
labels_batch <- batch[[2]]
features_batch <- conv_base %>% predict(inputs_batch)
index_range <- ((i * batch_size)+1):((i + 1) * batch_size) #Define the range to be loaded into
features[index_range,,,] <- features_batch #Loads features into the index range in the object featurs
labels[index_range] <- labels_batch #Same principle as above
# This step appear to take the first column from the one-hot encoded
i <- i + 1
print(i)
if (i * batch_size >= sample_count)
break
}
list(
features = features,
labels = labels
)
}
train <- extract_features(train_dir
, 4830) #This is the amount of picturs. There are in fact 4838, but for some reason this does not work
library(keras)
max_features <- 10000 #We want 10.000 words
maxlen <- 500 #Cutting off text at 500 words.
imdb <- dataset_imdb(num_words = max_features)
c(c(x_train, y_train), c(x_test, y_test)) %<-% imdb
x_train <- lapply(x_train,FUN =  rev) #Rev puts it in reverse order
x_test <- lapply(x_test,FUN =  rev) #Rev puts it in reverse order
x_train <- pad_sequences(x_train, maxlen = maxlen) #We apply padding again to have equal lengths
x_test <- pad_sequences(x_test, maxlen = maxlen) #We apply padding again to have equal lengths
model <- keras_model_sequential() %>%
layer_embedding(input_dim = max_features, output_dim = 128) %>%
layer_lstm(units = 32) %>%
layer_dense(units = 1, activation = "sigmoid")
model %>% compile(
optimizer = "rmsprop",
loss = "binary_crossentropy",
metrics = c("acc")
)
history <- model %>% fit(
x_train, y_train,
epochs = 10,
batch_size = 128,
validation_split = 0.2
)
library(doParallel)
CoreCount  <- makePSOCKcluster(detectCores()-1)
registerDoParallel(CoreCount)
history <- model %>% fit(
x_train, y_train,
epochs = 10,
batch_size = 128,
validation_split = 0.2
)
